"""
Simplified Natural Language to SQL Agentic System using CrewAI
This version uses a more straightforward approach with better error handling
"""

import json
import pandas as pd
from typing import Dict, List, Any, Optional
import duckdb
from sqlalchemy import create_engine, inspect
import google.generativeai as genai
from crewai import Agent, Task, Crew, Process
from langchain.tools import StructuredTool
from langchain.pydantic_v1 import BaseModel, Field
import matplotlib.pyplot as plt
import seaborn as sns
from io import BytesIO
import base64
import traceback
import time
import logging
from functools import wraps

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Configuration
class Config:
    GEMINI_API_KEY = "your-gemini-api-key"
    DUCKDB_PATH = "data_warehouse.duckdb"
    MAX_RETRIES = 3
    RETRY_DELAY = 1

# Initialize Gemini
genai.configure(api_key=Config.GEMINI_API_KEY)
gemini_model = genai.GenerativeModel('gemini-1.5-pro')

# Retry decorator
def retry_on_error(max_retries=Config.MAX_RETRIES, delay=Config.RETRY_DELAY):
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            last_exception = None
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    last_exception = e
                    logger.warning(f"Attempt {attempt + 1} failed: {str(e)}")
                    if attempt < max_retries - 1:
                        time.sleep(delay)
            raise last_exception
        return wrapper
    return decorator

# Database Manager
class DatabaseManager:
    def __init__(self, db_path: str = Config.DUCKDB_PATH):
        self.db_path = db_path
        self.engine = create_engine(f'duckdb:///{db_path}')
        
    def insert_dataframes(self, dataframes: Dict[str, pd.DataFrame], metadata: Dict[str, Any]):
        """Insert dataframes into DuckDB"""
        with self.engine.connect() as conn:
            for table_name, df in dataframes.items():
                # Clean column names
                df.columns = [col.replace(' ', '_').lower() for col in df.columns]
                # Insert data
                df.to_sql(table_name, conn, if_exists='replace', index=False)
                logger.info(f"Inserted table: {table_name} with {len(df)} rows")
    
    def get_all_schemas(self) -> Dict[str, List[Dict[str, str]]]:
        """Get schemas of all tables"""
        inspector = inspect(self.engine)
        schemas = {}
        
        for table_name in inspector.get_table_names():
            columns = []
            for col in inspector.get_columns(table_name):
                columns.append({
                    'name': col['name'],
                    'type': str(col['type'])
                })
            schemas[table_name] = columns
            
        return schemas
    
    @retry_on_error()
    def execute_query(self, query: str) -> pd.DataFrame:
        """Execute SQL query and return results as DataFrame"""
        with self.engine.connect() as conn:
            return pd.read_sql(query, conn)

# Pydantic models for tool inputs
class QueryInput(BaseModel):
    query: str = Field(description="SQL query to execute")

class ChartInput(BaseModel):
    data_json: str = Field(description="JSON string of data to visualize")
    chart_type: str = Field(description="Type of chart: bar, line, scatter, pie")
    title: str = Field(default="Data Visualization", description="Chart title")

class SummaryInput(BaseModel):
    data_json: str = Field(description="JSON string of data to summarize")
    context: str = Field(default="", description="Context for summarization")

# Tool Functions
class QueryTools:
    def __init__(self, db_manager: DatabaseManager):
        self.db_manager = db_manager
        
    def execute_query(self, query: str) -> str:
        """Execute SQL query and return results as JSON string"""
        try:
            result_df = self.db_manager.execute_query(query)
            result = {
                "status": "success",
                "data": result_df.to_dict('records'),
                "row_count": len(result_df),
                "columns": list(result_df.columns)
            }
            return json.dumps(result)
        except Exception as e:
            result = {
                "status": "error",
                "error": str(e)
            }
            return json.dumps(result)
    
    def create_chart(self, data_json: str, chart_type: str, title: str) -> str:
        """Create a chart from data"""
        try:
            data = json.loads(data_json)
            
            if isinstance(data, dict) and 'data' in data:
                df = pd.DataFrame(data['data'])
            else:
                df = pd.DataFrame(data)
            
            if df.empty:
                return json.dumps({"status": "error", "error": "No data to visualize"})
            
            plt.figure(figsize=(10, 6))
            
            # Create chart based on type
            if chart_type == "bar" and len(df.columns) >= 2:
                df.plot(x=df.columns[0], y=df.columns[1], kind='bar')
            elif chart_type == "line" and len(df.columns) >= 2:
                df.plot(x=df.columns[0], y=df.columns[1], kind='line')
            elif chart_type == "scatter" and len(df.columns) >= 2:
                plt.scatter(df[df.columns[0]], df[df.columns[1]])
                plt.xlabel(df.columns[0])
                plt.ylabel(df.columns[1])
            elif chart_type == "pie" and len(df.columns) >= 2:
                df.set_index(df.columns[0])[df.columns[1]].plot(kind='pie')
            else:
                # Default to table
                fig, ax = plt.subplots()
                ax.axis('tight')
                ax.axis('off')
                table_data = df.head(10).values
                table = ax.table(cellText=table_data,
                               colLabels=df.columns,
                               cellLoc='center',
                               loc='center')
                table.auto_set_font_size(False)
                table.set_fontsize(9)
            
            plt.title(title)
            plt.tight_layout()
            
            # Convert to base64
            buffer = BytesIO()
            plt.savefig(buffer, format='png', dpi=150, bbox_inches='tight')
            buffer.seek(0)
            image_base64 = base64.b64encode(buffer.read()).decode()
            plt.close()
            
            return json.dumps({
                "status": "success",
                "chart_type": chart_type,
                "image_base64": image_base64
            })
        except Exception as e:
            return json.dumps({
                "status": "error",
                "error": str(e)
            })
    
    def summarize_data(self, data_json: str, context: str) -> str:
        """Summarize data using LLM"""
        try:
            data = json.loads(data_json)
            
            if isinstance(data, dict) and 'data' in data:
                df = pd.DataFrame(data['data'])
            else:
                df = pd.DataFrame(data)
            
            if df.empty:
                return "No data to summarize."
            
            # Prepare summary prompt
            prompt = f"""
            Summarize the following query results:
            
            Context: {context}
            
            Data Overview:
            - Total rows: {len(df)}
            - Columns: {', '.join(df.columns)}
            
            Sample data (first 5 rows):
            {df.head().to_string()}
            
            Statistical Summary:
            {df.describe().to_string() if len(df.select_dtypes(include=['number']).columns) > 0 else "No numerical data"}
            
            Please provide a concise, insightful summary of the results.
            """
            
            response = gemini_model.generate_content(prompt)
            return response.text
        except Exception as e:
            return f"Error in summarization: {str(e)}"

# SQL Generator
class SQLGenerator:
    def __init__(self, db_manager: DatabaseManager):
        self.db_manager = db_manager
        
    @retry_on_error()
    def generate_sql_and_plan(self, natural_query: str, metadata: Dict[str, Any]) -> Dict[str, Any]:
        """Generate SQL query and execution plan from natural language"""
        schemas = self.db_manager.get_all_schemas()
        
        # Prepare schema information
        schema_info = ""
        for table_name, columns in schemas.items():
            schema_info += f"\nTable: {table_name}\n"
            for col in columns:
                schema_info += f"  - {col['name']} ({col['type']})\n"
        
        prompt = f"""
        You are a SQL expert. Convert the following natural language query to SQL for DuckDB.
        
        Natural Language Query: {natural_query}
        
        Database Schema:
        {schema_info}
        
        Table Metadata:
        {json.dumps(metadata, indent=2)}
        
        Return a JSON response with this exact structure:
        {{
            "sql_query": "SELECT ...",
            "explanation": "Brief explanation",
            "visualization": {{
                "needed": true/false,
                "chart_type": "bar/line/scatter/pie",
                "title": "Chart Title"
            }},
            "summary_needed": true/false
        }}
        
        Guidelines:
        - Use proper DuckDB SQL syntax
        - Set visualization.needed=true only if data would benefit from a chart
        - Set summary_needed=true only for complex analytical queries
        - For simple lookups, set both to false
        """
        
        response = gemini_model.generate_content(prompt)
        
        try:
            # Extract JSON from response
            text = response.text
            start = text.find('{')
            end = text.rfind('}') + 1
            json_str = text[start:end]
            return json.loads(json_str)
        except:
            # Fallback
            return {
                "sql_query": response.text.strip(),
                "explanation": "Generated SQL query",
                "visualization": {"needed": False},
                "summary_needed": False
            }

# Main Crew System
class NLToSQLSystem:
    def __init__(self, db_path: str = Config.DUCKDB_PATH):
        self.db_manager = DatabaseManager(db_path)
        self.tools = QueryTools(self.db_manager)
        self.sql_generator = SQLGenerator(self.db_manager)
        
        # Create structured tools for CrewAI
        self.execute_tool = StructuredTool(
            name="execute_query",
            description="Execute SQL query on the database",
            func=self.tools.execute_query,
            args_schema=QueryInput
        )
        
        self.chart_tool = StructuredTool(
            name="create_chart",
            description="Create a chart from query results",
            func=self.tools.create_chart,
            args_schema=ChartInput
        )
        
        self.summary_tool = StructuredTool(
            name="summarize_data",
            description="Summarize query results using AI",
            func=self.tools.summarize_data,
            args_schema=SummaryInput
        )
    
    def create_crew(self, sql_plan: Dict[str, Any], natural_query: str) -> Crew:
        """Create a crew based on the execution plan"""
        
        # Create agents
        executor = Agent(
            role="Database Query Executor",
            goal="Execute SQL queries and return results",
            backstory="I am an expert at executing database queries efficiently.",
            tools=[self.execute_tool],
            verbose=True
        )
        
        visualizer = Agent(
            role="Data Visualization Expert",
            goal="Create meaningful charts from data",
            backstory="I specialize in creating clear, informative visualizations.",
            tools=[self.chart_tool],
            verbose=True
        )
        
        summarizer = Agent(
            role="Data Analysis Expert",
            goal="Provide insightful summaries of data",
            backstory="I analyze data and provide clear, actionable insights.",
            tools=[self.summary_tool],
            verbose=True
        )
        
        # Create tasks
        tasks = []
        
        # Task 1: Execute query
        execute_task = Task(
            description=f"Execute this SQL query and return the results: {sql_plan['sql_query']}",
            agent=executor,
            expected_output="JSON string containing query results"
        )
        tasks.append(execute_task)
        
        # Task 2: Create visualization if needed
        if sql_plan.get('visualization', {}).get('needed', False):
            viz_config = sql_plan['visualization']
            viz_task = Task(
                description=f"""Create a {viz_config.get('chart_type', 'bar')} chart from the query results.
                Use the output from the previous task as data_json.
                Set the title to: {viz_config.get('title', 'Query Results')}""",
                agent=visualizer,
                expected_output="JSON string with chart creation status",
                context=[execute_task]
            )
            tasks.append(viz_task)
        
        # Task 3: Summarize if needed
        if sql_plan.get('summary_needed', False):
            summary_task = Task(
                description=f"""Summarize the query results from the execution task.
                Use the output from the execute task as data_json.
                Context for summary: {natural_query}""",
                agent=summarizer,
                expected_output="Text summary of the results",
                context=[execute_task]
            )
            tasks.append(summary_task)
        
        # Create crew
        agents = [executor]
        if sql_plan.get('visualization', {}).get('needed', False):
            agents.append(visualizer)
        if sql_plan.get('summary_needed', False):
            agents.append(summarizer)
        
        crew = Crew(
            agents=agents,
            tasks=tasks,
            process=Process.sequential,
            verbose=True
        )
        
        return crew
    
    def process_query(self, natural_query: str, metadata: Dict[str, Any]) -> Dict[str, Any]:
        """Process a natural language query"""
        results = {
            "query": natural_query,
            "status": "processing"
        }
        
        try:
            # Step 1: Generate SQL and execution plan
            logger.info("Generating SQL and execution plan...")
            sql_plan = self.sql_generator.generate_sql_and_plan(natural_query, metadata)
            results["sql"] = sql_plan["sql_query"]
            results["explanation"] = sql_plan["explanation"]
            
            # Step 2: Create and run crew
            logger.info("Creating and running crew...")
            crew = self.create_crew(sql_plan, natural_query)
            crew_output = crew.kickoff()
            
            # Step 3: Process results
            results["raw_output"] = str(crew_output)
            results["status"] = "success"
            
            # Parse individual task results
            if hasattr(crew_output, 'tasks_output'):
                results["task_results"] = []
                for task_output in crew_output.tasks_output:
                    results["task_results"].append({
                        "task": task_output.description[:50] + "...",
                        "output": str(task_output.raw_output)
                    })
            
        except Exception as e:
            logger.error(f"Error processing query: {str(e)}")
            logger.error(traceback.format_exc())
            results["status"] = "error"
            results["error"] = str(e)
            results["traceback"] = traceback.format_exc()
        
        return results
    
    def load_data(self, dataframes: Dict[str, pd.DataFrame], metadata: Dict[str, Any]):
        """Load data into the system"""
        self.db_manager.insert_dataframes(dataframes, metadata)

# Utility functions for testing and demo
def create_sample_data():
    """Create sample data for testing"""
    
    # Sample metadata
    metadata = {
        "tables": {
            "sales": {
                "description": "Sales transactions",
                "dependencies": ["products", "customers"]
            },
            "products": {
                "description": "Product catalog",
                "dependencies": []
            },
            "customers": {
                "description": "Customer information",
                "dependencies": []
            }
        }
    }
    
    # Sample dataframes
    dataframes = {
        "products": pd.DataFrame({
            "product_id": range(1, 6),
            "product_name": ["Laptop", "Mouse", "Keyboard", "Monitor", "Headphones"],
            "category": ["Electronics", "Accessories", "Accessories", "Electronics", "Accessories"],
            "price": [999.99, 29.99, 79.99, 299.99, 149.99]
        }),
        "customers": pd.DataFrame({
            "customer_id": range(1, 4),
            "customer_name": ["John Doe", "Jane Smith", "Bob Johnson"],
            "city": ["New York", "Los Angeles", "Chicago"],
            "join_date": pd.to_datetime(["2023-01-15", "2023-02-20", "2023-03-10"])
        }),
        "sales": pd.DataFrame({
            "sale_id": range(1, 11),
            "product_id": [1, 2, 1, 3, 4, 5, 2, 3, 1, 4],
            "customer_id": [1, 2, 3, 1, 2, 3, 1, 2, 3, 1],
            "quantity": [1, 2, 1, 1, 1, 2, 3, 1, 1, 1],
            "sale_date": pd.date_range("2024-01-01", periods=10, freq="D"),
            "total_amount": [999.99, 59.98, 999.99, 79.99, 299.99, 299.98, 89.97, 79.99, 999.99, 299.99]
        })
    }
    
    return dataframes, metadata

# Main execution
if __name__ == "__main__":
    # Create sample data
    dataframes, metadata = create_sample_data()
    
    # Initialize system
    system = NLToSQLSystem()
    
    # Load data
    print("Loading sample data...")
    system.load_data(dataframes, metadata)
    
    # Test queries
    test_queries = [
        "Show me total sales by product",
        "Which customer has spent the most money?",
        "Create a bar chart showing sales by category",
        "Give me a summary of customer purchasing patterns"
    ]
    
    for query in test_queries:
        print(f"\n{'='*60}")
        print(f"Query: {query}")
        print(f"{'='*60}")
        
        result = system.process_query(query, metadata)
        
        print(f"\nStatus: {result['status']}")
        print(f"SQL: {result.get('sql', 'N/A')}")
        print(f"Explanation: {result.get('explanation', 'N/A')}")
        
        if result['status'] == 'error':
            print(f"Error: {result['error']}")
        else:
            print(f"Output Preview: {str(result.get('raw_output', ''))[:200]}...")
